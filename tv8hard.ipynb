{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "1oTvimmyCW3m",
        "outputId": "e2da95b2-bb6e-465a-cc31-c015ff319ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.12/dist-packages (3.31.10)\n",
            "Collecting cmake\n",
            "  Downloading cmake-4.2.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.5 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmake-4.2.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (28.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.9/28.9 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip, cmake\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.31.10\n",
            "    Uninstalling cmake-3.31.10:\n",
            "      Successfully uninstalled cmake-3.31.10\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cmake-4.2.0 pip-25.3 setuptools-80.9.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b7a0bf66c4ef418f8c815e249a86b562",
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 1. Обновляем pip и устанавливаем инструменты сборки (это помогает при компиляции)\n",
        "!pip install --upgrade pip setuptools wheel cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8tzYUWSCw0u",
        "outputId": "5772ceda-f70d-4155-c7e4-ffe8f0b70f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (3.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install Cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bMKNUGu2CzNf"
      },
      "outputs": [],
      "source": [
        "# 2. Устанавливаем библиотеки по очереди (так надежнее)\n",
        "!pip install catboost\n",
        "!pip install pandas numpy scikit-learn\n",
        "\n",
        "# 3. Устанавливаем implicit с флагом verbose, чтобы видеть процесс (если будет компилироваться долго)\n",
        "# Обычно после установки cmake дело идет быстрее\n",
        "!pip install implicit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7IwLLguC7_A",
        "outputId": "42ba0692-b881-4f59-e0dc-f946c887e3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strict Config loaded.\n",
            "Config loaded.\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sparse\n",
        "import implicit\n",
        "from catboost import CatBoostRanker, Pool\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.decomposition import TruncatedSVD, PCA\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "# --- MASTER CONFIGURATION (STRICT MODE) ---\n",
        "class Config:\n",
        "    RANDOM_STATE = 42\n",
        "    VAL_SIZE = 0.1\n",
        "\n",
        "    # Настройки ALS\n",
        "    ALS_FACTORS = 64\n",
        "    ALS_REGULARIZATION = 0.05\n",
        "    ALS_ITERATIONS = 15\n",
        "    N_FOLDS_ALS = 5           # 5 фолдов - золотой стандарт\n",
        "\n",
        "    # Генерация кандидатов\n",
        "    TOP_K_CANDIDATES = 40     # Hard Negatives от ALS\n",
        "    NUM_RANDOM_NEGS = 0     # Random Negatives (для баланса)\n",
        "\n",
        "    # Настройки NLP\n",
        "    USE_BERT = True         # Включено\n",
        "    BERT_MODEL = 'cointegrated/rubert-tiny2'\n",
        "    BERT_PCA_COMPONENTS = 32\n",
        "\n",
        "\n",
        "    USE_TFIDF=True\n",
        "    TFIDF_MAX_FEATURES=5000\n",
        "    TFIDF_SVD_COMPONENTS=24\n",
        "\n",
        "\n",
        "\n",
        "    # Фичи\n",
        "    USE_META_FEATURES = True\n",
        "    USE_LOO_STATS = True      # Оставляем Leave-One-Out (безопасно)\n",
        "    USE_TIME_FEATURES = True\n",
        "\n",
        "    CAT_COLS = ['author_id', 'publisher', 'language', 'category_id']\n",
        "\n",
        "CFG = Config()\n",
        "print(\"Strict Config loaded.\")\n",
        "\n",
        "# Функция оптимизации памяти (Обязательная)\n",
        "def reduce_mem_usage(df):\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        if col_type != object and not str(col_type).startswith('datetime'):\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "    print(f'Memory usage reduced to {df.memory_usage().sum() / 1024**2:.2f} MB')\n",
        "    return df\n",
        "\n",
        "print(\"Config loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr0fdU_8DI0s",
        "outputId": "401b7e02-0fde-4ee6-c958-429794433ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Memory usage reduced to 4.62 MB\n",
            "Memory usage reduced to 0.04 MB\n",
            "Memory usage reduced to 1.81 MB\n",
            "Users: 7289, Items: 55784\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading data...\")\n",
        "# Замените пути на свои\n",
        "train_df = pd.read_csv('train.csv', parse_dates=['timestamp'])\n",
        "candidates_df = pd.read_csv('candidates.csv')\n",
        "users_df = pd.read_csv('users.csv')\n",
        "books_df = pd.read_csv('books.csv')\n",
        "book_descriptions = pd.read_csv(\"book_descriptions.csv\")\n",
        "\n",
        "# Оптимизация\n",
        "train_df = reduce_mem_usage(train_df)\n",
        "users_df = reduce_mem_usage(users_df)\n",
        "books_df = reduce_mem_usage(books_df)\n",
        "\n",
        "# Глобальные маппинги ID (важно для ALS)\n",
        "unique_users = train_df['user_id'].unique()\n",
        "unique_items = books_df['book_id'].unique()\n",
        "\n",
        "user2idx = {u: i for i, u in enumerate(unique_users)}\n",
        "item2idx = {i: k for k, i in enumerate(unique_items)}\n",
        "idx2user = {i: u for u, i in user2idx.items()}\n",
        "idx2item = {k: i for i, k in item2idx.items()}\n",
        "\n",
        "num_users = len(unique_users)\n",
        "num_items = len(unique_items)\n",
        "\n",
        "print(f\"Users: {num_users}, Items: {num_items}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270,
          "referenced_widgets": [
            "743103ca1d6d4c2bbbb0a6641be8842e",
            "01441ef57d044a749fe934712758e209",
            "10ff74fdea14428ab9aebb64768a9f90",
            "e1687840b552470d91e4583ae6150400",
            "a2a70190b1824ca4a9565926761553a1",
            "d10fc4429c134215bc9834bbb29956b5",
            "c7f997ce9c524b5ebf15bb74e35c1ad2",
            "b52821cda75c4c8fbc093f2a1199e0a4",
            "e276244cf0014f0682f880e45b716ba5",
            "040daca9a0924acf9418326303ab142a",
            "3850205b87cf4772be82fd1072f0079d"
          ]
        },
        "id": "MA-H7RjcDPuH",
        "outputId": "bd18c28a-648b-4f06-9d4e-14eb621eb31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Processing Text Features ---\n",
            "Running TF-IDF + SVD...\n",
            "Running BERT (cointegrated/rubert-tiny2)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/872 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "743103ca1d6d4c2bbbb0a6641be8842e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reducing BERT dimensions with PCA...\n",
            "Memory usage reduced to 6.17 MB\n"
          ]
        }
      ],
      "source": [
        "def process_text_features(desc_df):\n",
        "    print(\"--- Processing Text Features ---\")\n",
        "    desc_df['description'] = desc_df['description'].fillna('')\n",
        "    final_emb_df = pd.DataFrame({'book_id': desc_df['book_id']})\n",
        "\n",
        "    # 1. TF-IDF + SVD\n",
        "    if CFG.USE_TFIDF:\n",
        "        print(\"Running TF-IDF + SVD...\")\n",
        "        tfidf = TfidfVectorizer(max_features=CFG.TFIDF_MAX_FEATURES, stop_words='english')\n",
        "        tfidf_mat = tfidf.fit_transform(desc_df['description'])\n",
        "\n",
        "        svd = TruncatedSVD(n_components=CFG.TFIDF_SVD_COMPONENTS, random_state=CFG.RANDOM_STATE)\n",
        "        svd_mat = svd.fit_transform(tfidf_mat)\n",
        "\n",
        "        cols = [f'tfidf_svd_{i}' for i in range(CFG.TFIDF_SVD_COMPONENTS)]\n",
        "        temp_df = pd.DataFrame(svd_mat, columns=cols)\n",
        "        final_emb_df = pd.concat([final_emb_df, temp_df], axis=1)\n",
        "\n",
        "    # 2. BERT + PCA\n",
        "    if CFG.USE_BERT:\n",
        "        print(f\"Running BERT ({CFG.BERT_MODEL})...\")\n",
        "        model_bert = SentenceTransformer(CFG.BERT_MODEL)\n",
        "        # Если есть GPU, используем его\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        model_bert.to(device)\n",
        "\n",
        "        # Получаем эмбеддинги (это может занять время, но rubert-tiny быстрый)\n",
        "        embeddings = model_bert.encode(\n",
        "            desc_df['description'].tolist(),\n",
        "            show_progress_bar=True,\n",
        "            batch_size=64,\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        # Сжимаем PCA\n",
        "        print(\"Reducing BERT dimensions with PCA...\")\n",
        "        pca = PCA(n_components=CFG.BERT_PCA_COMPONENTS, random_state=CFG.RANDOM_STATE)\n",
        "        bert_pca = pca.fit_transform(embeddings)\n",
        "\n",
        "        cols = [f'bert_pca_{i}' for i in range(CFG.BERT_PCA_COMPONENTS)]\n",
        "        temp_df = pd.DataFrame(bert_pca, columns=cols)\n",
        "        final_emb_df = pd.concat([final_emb_df, temp_df], axis=1)\n",
        "\n",
        "    return reduce_mem_usage(final_emb_df)\n",
        "\n",
        "# Запускаем обработку текста\n",
        "if book_descriptions is not None:\n",
        "    text_features_df = process_text_features(book_descriptions)\n",
        "else:\n",
        "    text_features_df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N-U3A7MDDUb5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.sparse as sparse\n",
        "import implicit\n",
        "from sklearn.model_selection import KFold\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "# Маппинги должны быть уже созданы ранее, но на всякий случай обновим их глобально\n",
        "unique_users = train_df['user_id'].unique()\n",
        "unique_items = books_df['book_id'].unique()\n",
        "user2idx = {u: i for i, u in enumerate(unique_users)}\n",
        "item2idx = {i: k for k, i in enumerate(unique_items)}\n",
        "idx2user = {i: u for u, i in user2idx.items()}\n",
        "idx2item = {k: i for i, k in item2idx.items()}\n",
        "num_users, num_items = len(unique_users), len(unique_items)\n",
        "\n",
        "def generate_hybrid_train_data_v8(df, n_hard=40, n_random=10, n_folds=5):\n",
        "    print(f\"--- [v8] Generating Hybrid Train Data (Global Candidates + OOF Scores) ---\")\n",
        "\n",
        "    # === ЭТАП 1: Обучение Глобальной ALS (для выбора кандидатов) ===\n",
        "    print(\"1. Training Global ALS (Candidate Selection)...\")\n",
        "    rows = df['user_id'].map(user2idx).values\n",
        "    cols = df['book_id'].map(item2idx).values\n",
        "    # Создаем полную матрицу взаимодействий\n",
        "    sparse_global = sparse.csr_matrix((np.ones(len(rows)), (rows, cols)), shape=(num_users, num_items))\n",
        "\n",
        "    global_model = implicit.als.AlternatingLeastSquares(\n",
        "        factors=CFG.ALS_FACTORS,\n",
        "        regularization=CFG.ALS_REGULARIZATION,\n",
        "        iterations=CFG.ALS_ITERATIONS,\n",
        "        random_state=CFG.RANDOM_STATE,\n",
        "        use_gpu=torch.cuda.is_available()\n",
        "    )\n",
        "    global_model.fit(sparse_global, show_progress=True)\n",
        "\n",
        "    # === ЭТАП 2: Сборка структуры датасета (Строки) ===\n",
        "    print(f\"2. Constructing Dataset Skeleton (Pos + {n_hard} Hard + {n_random} Random)...\")\n",
        "\n",
        "    # А) Позитивы (Target: 2 = Read, 1 = Planned)\n",
        "    pos_df = df[['user_id', 'book_id', 'has_read']].copy()\n",
        "    pos_df['target'] = pos_df['has_read'].apply(lambda x: 2.0 if x == 1 else 1.0)\n",
        "    pos_df.drop(columns=['has_read'], inplace=True)\n",
        "\n",
        "    # Б) Hard Negatives (Target: 0) - берем топ рекомендаций глобальной модели\n",
        "    # Это самые \"сложные\" примеры, где модель ошибается\n",
        "    all_users_idx = np.arange(num_users)\n",
        "    ids, _ = global_model.recommend(\n",
        "        all_users_idx,\n",
        "        sparse_global[all_users_idx],\n",
        "        N=n_hard,\n",
        "        filter_already_liked_items=True\n",
        "    )\n",
        "\n",
        "    neg_data = []\n",
        "    # Разворачиваем рекомендации\n",
        "    for i, u_idx in enumerate(all_users_idx):\n",
        "        u_id = idx2user[u_idx]\n",
        "        for b_idx in ids[i]:\n",
        "            # Target 0\n",
        "            neg_data.append([u_id, idx2item[b_idx], 0.0])\n",
        "\n",
        "    # В) Random Negatives (Target: 0) - для разнообразия и робастности\n",
        "    rnd_data = []\n",
        "    if n_random > 0:\n",
        "        for u_idx in all_users_idx:\n",
        "            u_id = idx2user[u_idx]\n",
        "            # Выбираем случайные книги (можно оптимизировать, но цикл надежнее)\n",
        "            rand_items_idx = np.random.randint(0, num_items, n_random)\n",
        "            for r_idx in rand_items_idx:\n",
        "                rnd_data.append([u_id, idx2item[r_idx], 0.0])\n",
        "\n",
        "    # Сборка\n",
        "    neg_df = pd.DataFrame(neg_data, columns=['user_id', 'book_id', 'target'])\n",
        "    rnd_df = pd.DataFrame(rnd_data, columns=['user_id', 'book_id', 'target'])\n",
        "\n",
        "    full_df = pd.concat([pos_df, neg_df, rnd_df], ignore_index=True)\n",
        "\n",
        "    # Удаляем дубликаты (Приоритет: Pos > Hard > Random)\n",
        "    full_df.sort_values(by='target', ascending=False, inplace=True)\n",
        "    full_df.drop_duplicates(subset=['user_id', 'book_id'], keep='first', inplace=True)\n",
        "\n",
        "    # Инициализируем колонки для OOF скоров (пока пустые)\n",
        "    full_df['als_score'] = np.nan\n",
        "    full_df['als_item_norm'] = np.nan\n",
        "\n",
        "    # Помечаем реальные позитивы, чтобы знать, что исключать при OOF обучении\n",
        "    # Создаем set для быстрой проверки: (u_idx, b_idx)\n",
        "    real_interactions = set(zip(\n",
        "        pos_df['user_id'].map(user2idx).values,\n",
        "        pos_df['book_id'].map(item2idx).values\n",
        "    ))\n",
        "\n",
        "    print(f\"Skeleton created. Rows: {len(full_df)}. Starting OOF Scoring...\")\n",
        "\n",
        "    # === ЭТАП 3: OOF Scoring (Честный расчет скоров) ===\n",
        "    # Разбиваем ВЕСЬ full_df на фолды. Для каждого фолда обучаем ALS заново,\n",
        "    # ИСКЛЮЧАЯ из обучения те позитивы, которые попали в валидацию.\n",
        "\n",
        "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=CFG.RANDOM_STATE)\n",
        "\n",
        "    # Исходные данные для матрицы (все взаимодействия)\n",
        "    train_u_indices = df['user_id'].map(user2idx).values\n",
        "    train_b_indices = df['book_id'].map(item2idx).values\n",
        "\n",
        "    fold_cnt = 0\n",
        "    for _, val_idx in kf.split(full_df):\n",
        "        fold_cnt += 1\n",
        "\n",
        "        # Строки, которые мы сейчас будем скорить\n",
        "        current_rows = full_df.iloc[val_idx]\n",
        "\n",
        "        # Находим среди них те, которые являются РЕАЛЬНЫМИ позитивами\n",
        "        # Их нужно \"спрятать\" от ALS\n",
        "        current_u_idxs = current_rows['user_id'].map(user2idx).fillna(-1).astype(int).values\n",
        "        current_b_idxs = current_rows['book_id'].map(item2idx).fillna(-1).astype(int).values\n",
        "\n",
        "        # Собираем пары (u, i), которые надо исключить из обучения\n",
        "        pairs_to_exclude = set()\n",
        "        for u, b in zip(current_u_idxs, current_b_idxs):\n",
        "            if (u, b) in real_interactions:\n",
        "                pairs_to_exclude.add((u, b))\n",
        "\n",
        "        # Строим обучающую матрицу для этого фолда\n",
        "        # Фильтруем исходный train_df\n",
        "        mask_keep = []\n",
        "        for u, b in zip(train_u_indices, train_b_indices):\n",
        "            if (u, b) in pairs_to_exclude:\n",
        "                mask_keep.append(False)\n",
        "            else:\n",
        "                mask_keep.append(True)\n",
        "\n",
        "        mask_keep = np.array(mask_keep)\n",
        "\n",
        "        # Создаем разреженную матрицу (без валидационных позитивов)\n",
        "        sparse_fold = sparse.csr_matrix(\n",
        "            (np.ones(mask_keep.sum()), (train_u_indices[mask_keep], train_b_indices[mask_keep])),\n",
        "            shape=(num_users, num_items)\n",
        "        )\n",
        "\n",
        "        # Обучаем ALS для фолда\n",
        "        model_fold = implicit.als.AlternatingLeastSquares(\n",
        "            factors=CFG.ALS_FACTORS, regularization=CFG.ALS_REGULARIZATION,\n",
        "            iterations=CFG.ALS_ITERATIONS, random_state=CFG.RANDOM_STATE,\n",
        "            use_gpu=torch.cuda.is_available()\n",
        "        )\n",
        "        model_fold.fit(sparse_fold, show_progress=False)\n",
        "\n",
        "        # Предсказываем (Dot Product)\n",
        "        if hasattr(model_fold.user_factors, \"to_numpy\"):\n",
        "            u_fact = model_fold.user_factors.to_numpy()\n",
        "            i_fact = model_fold.item_factors.to_numpy()\n",
        "        else:\n",
        "            u_fact = model_fold.user_factors\n",
        "            i_fact = model_fold.item_factors\n",
        "\n",
        "        # Берем вектора для текущих юзеров и книг (даже если юзер был удален из трейна, вектор будет, хоть и плохой)\n",
        "        # Обработка -1 не нужна, так как skeleton построен на известных ID\n",
        "        vectors_u = u_fact[current_u_idxs]\n",
        "        vectors_b = i_fact[current_b_idxs]\n",
        "\n",
        "        scores = (vectors_u * vectors_b).sum(axis=1)\n",
        "        norms = np.linalg.norm(vectors_b, axis=1)\n",
        "\n",
        "        # Записываем\n",
        "        full_df.iloc[val_idx, full_df.columns.get_loc('als_score')] = scores\n",
        "        full_df.iloc[val_idx, full_df.columns.get_loc('als_item_norm')] = norms\n",
        "\n",
        "        print(f\"Fold {fold_cnt}/{n_folds} scored.\")\n",
        "\n",
        "        # Чистим память\n",
        "        del model_fold, sparse_fold, vectors_u, vectors_b\n",
        "        gc.collect()\n",
        "\n",
        "    full_df = full_df.sample(frac=1, random_state=CFG.RANDOM_STATE).reset_index(drop=True)\n",
        "    print(f\"Hybrid Dataset v8 Ready.\\nTarget Counts:\\n{full_df['target'].value_counts()}\")\n",
        "\n",
        "    return reduce_mem_usage(full_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HXWVKxMDDcBU"
      },
      "outputs": [],
      "source": [
        "# Предварительный расчет ГЛОБАЛЬНЫХ статистик (один раз на весь ноутбук)\n",
        "# Добавляем \"дочитываемость\" (read_ratio) - сильная фича из v4\n",
        "global_book_stats = train_df.groupby('book_id').agg({\n",
        "    'rating': ['mean', 'count'],\n",
        "    'has_read': ['mean', 'sum']\n",
        "})\n",
        "global_book_stats.columns = ['book_mean', 'book_count', 'book_read_ratio', 'book_read_sum']\n",
        "\n",
        "global_user_stats = train_df.groupby('user_id').agg({\n",
        "    'rating': ['mean', 'count'],\n",
        "    'has_read': ['mean', 'sum']\n",
        "})\n",
        "global_user_stats.columns = ['user_mean', 'user_count', 'user_read_ratio', 'user_read_sum']\n",
        "\n",
        "# Глобальные средние для заполнения пропусков\n",
        "GLOBAL_MEAN_RATING = train_df['rating'].mean()\n",
        "GLOBAL_MEAN_READ = train_df['has_read'].mean()\n",
        "\n",
        "def feature_engineering_v8(df):\n",
        "    print(f\"--- Feature Engineering v8 (Consistent/No-LOO) ---\")\n",
        "    out_df = df.copy()\n",
        "\n",
        "    # 1. Meta Features\n",
        "    if CFG.USE_META_FEATURES:\n",
        "        out_df = out_df.merge(users_df, on='user_id', how='left')\n",
        "        out_df = out_df.merge(books_df, on='book_id', how='left')\n",
        "        for c in CFG.CAT_COLS:\n",
        "            if c in out_df.columns:\n",
        "                out_df[c] = out_df[c].fillna(-1).astype(int)\n",
        "\n",
        "    # 2. Text Features (BERT/TF-IDF)\n",
        "    # Используем уже подготовленный text_features_df\n",
        "    if 'text_features_df' in globals() and text_features_df is not None:\n",
        "        out_df = out_df.merge(text_features_df, on='book_id', how='left')\n",
        "        feat_cols = [c for c in text_features_df.columns if c != 'book_id']\n",
        "        out_df[feat_cols] = out_df[feat_cols].fillna(0.0)\n",
        "\n",
        "    # 3. Statistics (Global Merge)\n",
        "    # Просто мержим. НЕ делаем вычитание (LOO).\n",
        "    # Это создает небольшой лик на трейне, но обеспечивает совпадение с тестом.\n",
        "    out_df = out_df.merge(global_book_stats, on='book_id', how='left')\n",
        "    out_df = out_df.merge(global_user_stats, on='user_id', how='left')\n",
        "\n",
        "    # Заполнение пропусков\n",
        "    out_df['book_mean'] = out_df['book_mean'].fillna(GLOBAL_MEAN_RATING)\n",
        "    out_df['book_count'] = out_df['book_count'].fillna(0)\n",
        "    out_df['book_read_ratio'] = out_df['book_read_ratio'].fillna(GLOBAL_MEAN_READ)\n",
        "    out_df['book_read_sum'] = out_df['book_read_sum'].fillna(0)\n",
        "\n",
        "    out_df['user_mean'] = out_df['user_mean'].fillna(GLOBAL_MEAN_RATING)\n",
        "    out_df['user_count'] = out_df['user_count'].fillna(0)\n",
        "    out_df['user_read_ratio'] = out_df['user_read_ratio'].fillna(GLOBAL_MEAN_READ)\n",
        "    out_df['user_read_sum'] = out_df['user_read_sum'].fillna(0)\n",
        "\n",
        "    # 4. Time Features\n",
        "    if CFG.USE_TIME_FEATURES:\n",
        "        cur_year = 2025\n",
        "        if 'publication_year' in out_df.columns:\n",
        "            out_df['publication_year'] = out_df['publication_year'].fillna(cur_year)\n",
        "            out_df['book_age'] = cur_year - out_df['publication_year']\n",
        "            # Клипаем выбросы\n",
        "            out_df['book_age'] = out_df['book_age'].clip(0, 200)\n",
        "\n",
        "    # Чистка лишнего\n",
        "    drops = ['title', 'author_name', 'description', 'timestamp', 'has_read']\n",
        "    out_df.drop([c for c in drops if c in out_df.columns], axis=1, inplace=True)\n",
        "\n",
        "    return reduce_mem_usage(out_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_oKY4IZ9_QVP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525,
          "referenced_widgets": [
            "e363977aa3194a46a43da56bb13c2c88",
            "62d666ef109349278c3196c9bbd54ba4",
            "72ac1e45f1c4437a87647def66c2dd2a",
            "6c5aec51640d40faa04fbf609cc52f91",
            "aaf40588d360480c8135edbaa0c1622b",
            "45d877a2d9f546b49f6eb46429a1e5fd",
            "858de7570ccd41d398175dd1d86c7bfa",
            "75efa02d069043cc9d73c7d155f94a16",
            "be629881cb914132bd4c5736ed109221",
            "59657b5a05f041b2a8f362aac76abcf9",
            "245de16688ad4f3093054604ed0b068f"
          ]
        },
        "outputId": "42cd01c3-8a11-4f9a-84ad-c96eb19c8974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [v8] Generating Hybrid Train Data (Global Candidates + OOF Scores) ---\n",
            "1. Training Global ALS (Candidate Selection)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e363977aa3194a46a43da56bb13c2c88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Constructing Dataset Skeleton (Pos + 40 Hard + 0 Random)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-401261207.py:77: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  full_df = pd.concat([pos_df, neg_df, rnd_df], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton created. Rows: 560621. Starting OOF Scoring...\n",
            "Fold 1/5 scored.\n",
            "Fold 2/5 scored.\n",
            "Fold 3/5 scored.\n",
            "Fold 4/5 scored.\n",
            "Fold 5/5 scored.\n",
            "Hybrid Dataset v8 Ready.\n",
            "Target Counts:\n",
            "target\n",
            "0.0    291560\n",
            "2.0    156603\n",
            "1.0    112458\n",
            "Name: count, dtype: int64\n",
            "Memory usage reduced to 11.76 MB\n",
            "--- Feature Engineering v8 (Consistent/No-LOO) ---\n",
            "Memory usage reduced to 88.75 MB\n",
            "\n",
            "Ready for CatBoost Training.\n",
            "Train Shape: (560638, 77)\n",
            "Columns: ['user_id', 'book_id', 'target', 'als_score', 'als_item_norm', 'gender', 'age', 'author_id', 'publication_year', 'language', 'publisher', 'avg_rating', 'tfidf_svd_0', 'tfidf_svd_1', 'tfidf_svd_2', 'tfidf_svd_3', 'tfidf_svd_4', 'tfidf_svd_5', 'tfidf_svd_6', 'tfidf_svd_7', 'tfidf_svd_8', 'tfidf_svd_9', 'tfidf_svd_10', 'tfidf_svd_11', 'tfidf_svd_12', 'tfidf_svd_13', 'tfidf_svd_14', 'tfidf_svd_15', 'tfidf_svd_16', 'tfidf_svd_17', 'tfidf_svd_18', 'tfidf_svd_19', 'tfidf_svd_20', 'tfidf_svd_21', 'tfidf_svd_22', 'tfidf_svd_23', 'bert_pca_0', 'bert_pca_1', 'bert_pca_2', 'bert_pca_3', 'bert_pca_4', 'bert_pca_5', 'bert_pca_6', 'bert_pca_7', 'bert_pca_8', 'bert_pca_9', 'bert_pca_10', 'bert_pca_11', 'bert_pca_12', 'bert_pca_13', 'bert_pca_14', 'bert_pca_15', 'bert_pca_16', 'bert_pca_17', 'bert_pca_18', 'bert_pca_19', 'bert_pca_20', 'bert_pca_21', 'bert_pca_22', 'bert_pca_23', 'bert_pca_24', 'bert_pca_25', 'bert_pca_26', 'bert_pca_27', 'bert_pca_28', 'bert_pca_29', 'bert_pca_30', 'bert_pca_31', 'book_mean', 'book_count', 'book_read_ratio', 'book_read_sum', 'user_mean', 'user_count', 'user_read_ratio', 'user_read_sum', 'book_age']\n"
          ]
        }
      ],
      "source": [
        "# 1. Генерируем \"честный\" обучающий датасет (включая позитивы и негативы)\n",
        "train_dataset = generate_hybrid_train_data_v8(train_df, n_hard=CFG.TOP_K_CANDIDATES, n_random=CFG.NUM_RANDOM_NEGS, n_folds=CFG.N_FOLDS_ALS)\n",
        "# 2. Навешиваем фичи (текстовые + статистики с LOO)\n",
        "# mode='train' включит защиту от лика таргета в статистиках\n",
        "X_train_strict = feature_engineering_v8(train_dataset)\n",
        "\n",
        "print(\"\\nReady for CatBoost Training.\")\n",
        "print(\"Train Shape:\", X_train_strict.shape)\n",
        "print(\"Columns:\", list(X_train_strict.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtR1v854DeNf",
        "outputId": "3a633810-1f3a-4e3a-982b-5ef4b7a385cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Feature Importance Audit ---\n",
            "Groupwise loss function. OneHotMaxSize set to 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because NDCG is/are not implemented for GPU\n",
            "Metric NDCG:type=Base is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
            "Metric NDCG:type=Base is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\ttotal: 111ms\tremaining: 1m 17s\n",
            "100:\ttotal: 6.34s\tremaining: 37.6s\n",
            "200:\ttotal: 13.5s\tremaining: 33.5s\n",
            "300:\ttotal: 19.6s\tremaining: 26s\n",
            "400:\ttotal: 27.9s\tremaining: 20.8s\n",
            "500:\ttotal: 34.2s\tremaining: 13.6s\n",
            "600:\ttotal: 41.1s\tremaining: 6.76s\n",
            "699:\ttotal: 47.1s\tremaining: 0us\n",
            "Top 50 Features:\n",
            "             feature  importance\n",
            "1      als_item_norm   29.941011\n",
            "0          als_score   23.276285\n",
            "67   book_read_ratio   20.844490\n",
            "70        user_count   10.431159\n",
            "72     user_read_sum    3.958656\n",
            "4          author_id    3.390608\n",
            "71   user_read_ratio    2.488555\n",
            "66        book_count    2.085889\n",
            "68     book_read_sum    1.617071\n",
            "8         avg_rating    0.597290\n",
            "65         book_mean    0.388901\n",
            "69         user_mean    0.247799\n",
            "36        bert_pca_3    0.223978\n",
            "33        bert_pca_0    0.176779\n",
            "38        bert_pca_5    0.085470\n",
            "10       tfidf_svd_1    0.025806\n",
            "60       bert_pca_27    0.019778\n",
            "45       bert_pca_12    0.019038\n",
            "56       bert_pca_23    0.018975\n",
            "42        bert_pca_9    0.013923\n",
            "7          publisher    0.011862\n",
            "11       tfidf_svd_2    0.011793\n",
            "24      tfidf_svd_15    0.009689\n",
            "16       tfidf_svd_7    0.008933\n",
            "37        bert_pca_4    0.007504\n",
            "26      tfidf_svd_17    0.007244\n",
            "61       bert_pca_28    0.006230\n",
            "17       tfidf_svd_8    0.005316\n",
            "58       bert_pca_25    0.005216\n",
            "47       bert_pca_14    0.005179\n",
            "23      tfidf_svd_14    0.004678\n",
            "52       bert_pca_19    0.004344\n",
            "35        bert_pca_2    0.004098\n",
            "13       tfidf_svd_4    0.004084\n",
            "51       bert_pca_18    0.003809\n",
            "44       bert_pca_11    0.003602\n",
            "22      tfidf_svd_13    0.003352\n",
            "48       bert_pca_15    0.003255\n",
            "34        bert_pca_1    0.003213\n",
            "9        tfidf_svd_0    0.002956\n",
            "5   publication_year    0.002920\n",
            "55       bert_pca_22    0.002893\n",
            "49       bert_pca_16    0.002853\n",
            "30      tfidf_svd_21    0.002833\n",
            "18       tfidf_svd_9    0.002595\n",
            "40        bert_pca_7    0.002275\n",
            "31      tfidf_svd_22    0.002139\n",
            "46       bert_pca_13    0.002046\n",
            "39        bert_pca_6    0.002023\n",
            "29      tfidf_svd_20    0.001865\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Feature Importance Audit ---\")\n",
        "X_train_full=X_train_strict\n",
        "# Подготовка данных для аудита\n",
        "# Сортировка по группам обязательна для YetiRank\n",
        "X_train_full.sort_values(by='user_id', inplace=True)\n",
        "\n",
        "audit_cols_drop = ['user_id', 'book_id', 'target']\n",
        "X_audit = X_train_full.drop(audit_cols_drop, axis=1)\n",
        "y_audit = X_train_full['target']\n",
        "group_audit = X_train_full['user_id']\n",
        "\n",
        "# Находим категориальные колонки, которые реально остались\n",
        "audit_cat = [c for c in CFG.CAT_COLS if c in X_audit.columns]\n",
        "\n",
        "# Используем быстрый Ranker\n",
        "audit_model = CatBoostRanker(\n",
        "    loss_function='YetiRank',\n",
        "    iterations=700,        # Мало итераций для скорости\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    task_type='GPU',       # Для аудита можно и CPU, если данных не миллионы\n",
        "    verbose= 100,\n",
        "    random_seed=CFG.RANDOM_STATE\n",
        ")\n",
        "\n",
        "audit_pool = Pool(\n",
        "    data=X_audit,\n",
        "    label=y_audit,\n",
        "    group_id=group_audit,\n",
        "    cat_features=audit_cat\n",
        ")\n",
        "\n",
        "audit_model.fit(audit_pool)\n",
        "\n",
        "# Вывод важности\n",
        "fi = audit_model.get_feature_importance(type='PredictionValuesChange')\n",
        "fi_df = pd.DataFrame({'feature': X_audit.columns, 'importance': fi}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Top 50 Features:\")\n",
        "print(fi_df.head(50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9f5beb30fc9d448eb98a3809800e7682",
            "cc088e47e8f442b38a196616ffe3cd38",
            "aab0e9aae1a949cdae837a079c64260c",
            "426692e0186b494faf5c448a45cd0741",
            "5b5eef9d7ac44613a827c2b940e92a3d",
            "ca244d9636454685a0335326bf6be460",
            "18ba7ac8ba544e1fb6772330ffe34d0a",
            "e985af947c844670aed47c14504eeca1",
            "b54a0702c7d14a29b98eca6123a65314",
            "46aa14e0f88340dfbfacbe8259fad255",
            "067ef0e4b06b430f91c439cd94fb1169"
          ]
        },
        "id": "uuJyakzWDgU8",
        "outputId": "27fc171e-b863-4253-ccea-db6b440dbd0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [v8] Generating Hybrid Train Data (Global Candidates + OOF Scores) ---\n",
            "1. Training Global ALS (Candidate Selection)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f5beb30fc9d448eb98a3809800e7682"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Constructing Dataset Skeleton (Pos + 40 Hard + 0 Random)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-401261207.py:77: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  full_df = pd.concat([pos_df, neg_df, rnd_df], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton created. Rows: 560621. Starting OOF Scoring...\n",
            "Fold 1/5 scored.\n",
            "Fold 2/5 scored.\n",
            "Fold 3/5 scored.\n",
            "Fold 4/5 scored.\n",
            "Fold 5/5 scored.\n",
            "Hybrid Dataset v8 Ready.\n",
            "Target Counts:\n",
            "target\n",
            "0.0    291560\n",
            "2.0    156603\n",
            "1.0    112458\n",
            "Name: count, dtype: int64\n",
            "Memory usage reduced to 11.76 MB\n",
            "--- Feature Engineering v8 (Consistent/No-LOO) ---\n",
            "Memory usage reduced to 88.75 MB\n",
            "\n",
            "--- Training CatBoost Ranker (v8) ---\n",
            "Features: 74\n",
            "Groupwise loss function. OneHotMaxSize set to 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because NDCG is/are not implemented for GPU\n",
            "Metric NDCG:type=Base is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
            "Metric NDCG:top=20;type=Base is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\ttest: 0.8191817\tbest: 0.8191817 (0)\ttotal: 177ms\tremaining: 11m 49s\n",
            "100:\ttest: 0.8931673\tbest: 0.8933153 (98)\ttotal: 8.28s\tremaining: 5m 19s\n",
            "200:\ttest: 0.8968344\tbest: 0.8968440 (199)\ttotal: 16.9s\tremaining: 5m 18s\n",
            "300:\ttest: 0.8987389\tbest: 0.8989000 (287)\ttotal: 24.3s\tremaining: 4m 58s\n",
            "400:\ttest: 0.9015429\tbest: 0.9015429 (400)\ttotal: 32.8s\tremaining: 4m 54s\n",
            "500:\ttest: 0.9027974\tbest: 0.9028187 (496)\ttotal: 42s\tremaining: 4m 53s\n",
            "600:\ttest: 0.9036075\tbest: 0.9036075 (600)\ttotal: 50.1s\tremaining: 4m 43s\n",
            "700:\ttest: 0.9045225\tbest: 0.9047275 (666)\ttotal: 58.6s\tremaining: 4m 35s\n",
            "800:\ttest: 0.9052398\tbest: 0.9053982 (783)\ttotal: 1m 6s\tremaining: 4m 25s\n",
            "900:\ttest: 0.9057752\tbest: 0.9057854 (882)\ttotal: 1m 14s\tremaining: 4m 17s\n",
            "1000:\ttest: 0.9058633\tbest: 0.9060735 (991)\ttotal: 1m 23s\tremaining: 4m 9s\n",
            "1100:\ttest: 0.9059357\tbest: 0.9060875 (1033)\ttotal: 1m 30s\tremaining: 3m 59s\n",
            "1200:\ttest: 0.9063308\tbest: 0.9064279 (1188)\ttotal: 1m 39s\tremaining: 3m 51s\n",
            "1300:\ttest: 0.9075118\tbest: 0.9075471 (1298)\ttotal: 1m 47s\tremaining: 3m 43s\n",
            "1400:\ttest: 0.9074915\tbest: 0.9080486 (1373)\ttotal: 1m 55s\tremaining: 3m 34s\n",
            "1500:\ttest: 0.9092064\tbest: 0.9093905 (1475)\ttotal: 2m 4s\tremaining: 3m 26s\n",
            "1600:\ttest: 0.9096350\tbest: 0.9096350 (1600)\ttotal: 2m 11s\tremaining: 3m 17s\n",
            "1700:\ttest: 0.9099727\tbest: 0.9099727 (1699)\ttotal: 2m 20s\tremaining: 3m 9s\n",
            "1800:\ttest: 0.9096653\tbest: 0.9099834 (1702)\ttotal: 2m 28s\tremaining: 3m 1s\n",
            "1900:\ttest: 0.9101248\tbest: 0.9102067 (1883)\ttotal: 2m 36s\tremaining: 2m 52s\n",
            "2000:\ttest: 0.9101235\tbest: 0.9103720 (1976)\ttotal: 2m 44s\tremaining: 2m 44s\n",
            "2100:\ttest: 0.9101458\tbest: 0.9103727 (2072)\ttotal: 2m 52s\tremaining: 2m 36s\n",
            "2200:\ttest: 0.9102221\tbest: 0.9103727 (2072)\ttotal: 3m 1s\tremaining: 2m 28s\n",
            "bestTest = 0.9103726747\n",
            "bestIteration = 2072\n",
            "Shrink model to first 2073 iterations.\n",
            "Best Score: {}\n"
          ]
        }
      ],
      "source": [
        "# 1. Генерация данных\n",
        "train_dataset_v8 = generate_hybrid_train_data_v8(train_df, n_hard=CFG.TOP_K_CANDIDATES, n_random=CFG.NUM_RANDOM_NEGS, n_folds=CFG.N_FOLDS_ALS)\n",
        "\n",
        "# 2. Генерация фичей\n",
        "X_train_v8 = feature_engineering_v8(train_dataset_v8)\n",
        "\n",
        "print(\"\\n--- Training CatBoost Ranker (v8) ---\")\n",
        "# Сортировка для групповой обработки\n",
        "X_train_v8.sort_values(by='user_id', inplace=True)\n",
        "\n",
        "# Сплит\n",
        "train_users, val_users = train_test_split(\n",
        "    X_train_v8['user_id'].unique(),\n",
        "    test_size=CFG.VAL_SIZE,\n",
        "    random_state=CFG.RANDOM_STATE\n",
        ")\n",
        "\n",
        "train_mask = X_train_v8['user_id'].isin(train_users)\n",
        "val_mask = X_train_v8['user_id'].isin(val_users)\n",
        "\n",
        "drop_cols = ['user_id', 'book_id', 'target']\n",
        "feat_cols = [c for c in X_train_v8.columns if c not in drop_cols]\n",
        "# Актуализируем список категориальных фичей\n",
        "cat_feats = [c for c in CFG.CAT_COLS if c in feat_cols]\n",
        "\n",
        "print(f\"Features: {len(feat_cols)}\")\n",
        "\n",
        "train_pool = Pool(\n",
        "    data=X_train_v8.loc[train_mask, feat_cols],\n",
        "    label=X_train_v8.loc[train_mask, 'target'],\n",
        "    group_id=X_train_v8.loc[train_mask, 'user_id'],\n",
        "    cat_features=cat_feats\n",
        ")\n",
        "\n",
        "val_pool = Pool(\n",
        "    data=X_train_v8.loc[val_mask, feat_cols],\n",
        "    label=X_train_v8.loc[val_mask, 'target'],\n",
        "    group_id=X_train_v8.loc[val_mask, 'user_id'],\n",
        "    cat_features=cat_feats\n",
        ")\n",
        "\n",
        "# Параметры v8\n",
        "# YetiRank отлично работает с градациями 0, 1, 2\n",
        "params = {\n",
        "    'loss_function': 'YetiRank',\n",
        "    'iterations': 4000,\n",
        "    'learning_rate': 0.05,\n",
        "    'depth': 8,               # Увеличиваем глубину, т.к. данных стало больше (Hard+Random)\n",
        "    'l2_leaf_reg': 7,\n",
        "    'random_seed': CFG.RANDOM_STATE,\n",
        "    'eval_metric': 'NDCG:top=20',\n",
        "    'early_stopping_rounds': 150,\n",
        "    'verbose': 100,\n",
        "    'task_type': 'GPU' if torch.cuda.is_available() else 'CPU'\n",
        "}\n",
        "\n",
        "model_v8 = CatBoostRanker(**params)\n",
        "model_v8.fit(train_pool, eval_set=val_pool)\n",
        "\n",
        "print(f\"Best Score: {model_v8.get_best_score()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKkCnxC5Di5l",
        "outputId": "61066de5-60c1-48f4-a0b3-26017dd613a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [v8] Final Inference & Submission ---\n",
            "Test pairs count: 81048\n",
            "Retraining Global ALS for Test Scoring...\n",
            "--- Feature Engineering v8 (Consistent/No-LOO) ---\n",
            "Memory usage reduced to 12.06 MB\n",
            "Shape after Feature Engineering: (81049, 76)\n",
            "Predicting with CatBoost...\n",
            "Submission saved to submission_v8_only_hard.csv\n",
            "   user_id                                       book_id_list\n",
            "0      210  2447113,3988468,1673950,971259,1281035,3015694...\n",
            "1     1380  2290484,2548861,482934,1326209,2231328,2356900...\n",
            "2     2050  460492,1021078,2053462,2254200,317849,822326,2...\n",
            "3     2740  987516,2107128,112023,1339705,5535190,2479424,...\n",
            "4     4621  2595660,2347566,2446687,1809950,2347564,196421...\n"
          ]
        }
      ],
      "source": [
        "print(\"--- [v8] Final Inference & Submission ---\")\n",
        "\n",
        "# 1. Готовим кандидатов\n",
        "candidates_exploded = []\n",
        "candidates_source = candidates_df.copy()\n",
        "\n",
        "for _, row in candidates_source.iterrows():\n",
        "    u_id = row['user_id']\n",
        "    if pd.isna(row['book_id_list']):\n",
        "        continue\n",
        "    b_ids = str(row['book_id_list']).split(',')\n",
        "    for b_id in b_ids:\n",
        "        if b_id:\n",
        "            candidates_exploded.append([u_id, int(b_id)])\n",
        "\n",
        "test_df = pd.DataFrame(candidates_exploded, columns=['user_id', 'book_id'])\n",
        "print(f\"Test pairs count: {len(test_df)}\")\n",
        "\n",
        "# 2. Считаем ALS Score\n",
        "print(\"Retraining Global ALS for Test Scoring...\")\n",
        "all_rows = train_df['user_id'].map(user2idx).values\n",
        "all_cols = train_df['book_id'].map(item2idx).values\n",
        "sparse_master = sparse.csr_matrix((np.ones(len(all_rows)), (all_rows, all_cols)), shape=(num_users, num_items))\n",
        "\n",
        "master_model = implicit.als.AlternatingLeastSquares(\n",
        "    factors=CFG.ALS_FACTORS, regularization=CFG.ALS_REGULARIZATION,\n",
        "    iterations=CFG.ALS_ITERATIONS, random_state=CFG.RANDOM_STATE,\n",
        "    use_gpu=torch.cuda.is_available()\n",
        ")\n",
        "master_model.fit(sparse_master, show_progress=False)\n",
        "\n",
        "# Предсказываем\n",
        "if hasattr(master_model.user_factors, \"to_numpy\"):\n",
        "    u_factors = master_model.user_factors.to_numpy()\n",
        "    i_factors = master_model.item_factors.to_numpy()\n",
        "else:\n",
        "    u_factors = master_model.user_factors\n",
        "    i_factors = master_model.item_factors\n",
        "\n",
        "test_u_idxs = test_df['user_id'].map(user2idx).fillna(-1).astype(int).values\n",
        "test_b_idxs = test_df['book_id'].map(item2idx).fillna(-1).astype(int).values\n",
        "\n",
        "test_scores = np.zeros(len(test_df))\n",
        "test_norms = np.zeros(len(test_df))\n",
        "mask = (test_u_idxs >= 0) & (test_b_idxs >= 0)\n",
        "\n",
        "if mask.sum() > 0:\n",
        "    test_scores[mask] = (u_factors[test_u_idxs[mask]] * i_factors[test_b_idxs[mask]]).sum(axis=1)\n",
        "    test_norms[mask] = np.linalg.norm(i_factors[test_b_idxs[mask]], axis=1)\n",
        "\n",
        "test_df['als_score'] = test_scores\n",
        "test_df['als_item_norm'] = test_norms\n",
        "\n",
        "# 3. Фичи\n",
        "# !!! ИСПРАВЛЕНИЕ ЗДЕСЬ !!!\n",
        "# Мы перезаписываем test_df, чтобы учесть возможное увеличение строк после merge\n",
        "test_df = feature_engineering_v8(test_df)\n",
        "print(f\"Shape after Feature Engineering: {test_df.shape}\")\n",
        "\n",
        "# 4. Проверка и выравнивание колонок\n",
        "expected_cols = model_v8.feature_names_\n",
        "# Создаем X_test на основе ОБНОВЛЕННОГО test_df\n",
        "X_test = test_df.copy()\n",
        "\n",
        "for col in expected_cols:\n",
        "    if col not in X_test.columns:\n",
        "        X_test[col] = 0\n",
        "X_test = X_test[expected_cols]\n",
        "\n",
        "# 5. Предсказание\n",
        "print(\"Predicting with CatBoost...\")\n",
        "final_scores = model_v8.predict(X_test)\n",
        "\n",
        "# Теперь длины гарантированно совпадают\n",
        "test_df['score'] = final_scores\n",
        "\n",
        "# 6. Сборка сабмита\n",
        "test_df_sorted = test_df.sort_values(['user_id', 'score'], ascending=[True, False])\n",
        "# Удаляем дубликаты, если они возникли при merge (берем с высшим скором)\n",
        "test_df_sorted = test_df_sorted.drop_duplicates(subset=['user_id', 'book_id'])\n",
        "\n",
        "grouped_preds = test_df_sorted.groupby('user_id')['book_id'].apply(list).reset_index()\n",
        "\n",
        "final_submission = candidates_source[['user_id']].merge(grouped_preds, on='user_id', how='left')\n",
        "\n",
        "def format_list(x):\n",
        "    if isinstance(x, list):\n",
        "        # Топ 20\n",
        "        return \",\".join([str(i) for i in x[:20]])\n",
        "    return \"\"\n",
        "\n",
        "final_submission['book_id_list'] = final_submission['book_id'].apply(format_list)\n",
        "final_submission = final_submission[['user_id', 'book_id_list']]\n",
        "\n",
        "# Сохранение\n",
        "save_name = 'submission_v8_only_hard.csv'\n",
        "final_submission.to_csv(save_name, index=False)\n",
        "print(f\"Submission saved to {save_name}\")\n",
        "print(final_submission.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMeDdWMS4xTH",
        "outputId": "60563c31-435e-4996-d447-ccab663765cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Created folder: /content/drive/MyDrive/NTO_RecSys_Data\n",
            "------------------------------\n",
            "✅ Saved: train.csv\n",
            "✅ Saved: candidates.csv\n",
            "✅ Saved: users.csv\n",
            "✅ Saved: books.csv\n",
            "✅ Saved: book_genres.csv\n",
            "✅ Saved: book_descriptions.csv\n",
            "------------------------------\n",
            "Backup complete. Files are in 'MyDrive/NTO_RecSys_Data'\n"
          ]
        }
      ],
      "source": [
        "# --- ЯЧЕЙКА: СОХРАНЕНИЕ ДАННЫХ НА GOOGLE DRIVE ---\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# 1. Подключаем Google Диск\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Настройки\n",
        "# Имя папки на Гугл Диске, куда все сохранится\n",
        "DRIVE_FOLDER_NAME = 'NTO_RecSys_Data'\n",
        "DESTINATION_PATH = f'/content/drive/MyDrive/{DRIVE_FOLDER_NAME}'\n",
        "\n",
        "# Список файлов, которые нужно сохранить (добавь сюда names, если есть другие)\n",
        "FILES_TO_SAVE = [\n",
        "    'train.csv',\n",
        "    'candidates.csv',\n",
        "    'users.csv',\n",
        "    'books.csv',\n",
        "    'book_genres.csv',\n",
        "    'book_descriptions.csv',\n",
        "    # 'submission_strict_v6_fixed.csv' # раскомментируй, если хочешь сохранить и результат\n",
        "]\n",
        "\n",
        "# 3. Создаем папку на диске, если её нет\n",
        "if not os.path.exists(DESTINATION_PATH):\n",
        "    os.makedirs(DESTINATION_PATH)\n",
        "    print(f\"Created folder: {DESTINATION_PATH}\")\n",
        "else:\n",
        "    print(f\"Folder exists: {DESTINATION_PATH}\")\n",
        "\n",
        "# 4. Копируем файлы\n",
        "print(\"-\" * 30)\n",
        "for file_name in FILES_TO_SAVE:\n",
        "    if os.path.exists(file_name):\n",
        "        try:\n",
        "            shutil.copy2(file_name, f\"{DESTINATION_PATH}/{file_name}\")\n",
        "            print(f\"✅ Saved: {file_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error saving {file_name}: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠️ File not found in Colab: {file_name}\")\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(f\"Backup complete. Files are in 'MyDrive/{DRIVE_FOLDER_NAME}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdmLBhiO5Ec-"
      },
      "outputs": [],
      "source": [
        "# --- ЯЧЕЙКА: ЗАГРУЗКА ДАННЫХ С GOOGLE DRIVE ---\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# 1. Подключаем Google Диск\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 2. Настройки\n",
        "# Та же папка, что и в первой ячейке\n",
        "DRIVE_FOLDER_NAME = 'NTO_RecSys_Data'\n",
        "SOURCE_PATH = f'/content/drive/MyDrive/{DRIVE_FOLDER_NAME}'\n",
        "DESTINATION_PATH = '/content'  # Текущая рабочая директория Colab\n",
        "\n",
        "# 3. Копирование файлов\n",
        "print(\"-\" * 30)\n",
        "if os.path.exists(SOURCE_PATH):\n",
        "    files = os.listdir(SOURCE_PATH)\n",
        "    count = 0\n",
        "    for file_name in files:\n",
        "        # Копируем только файлы (не папки) и исключаем системные файлы\n",
        "        full_file_name = os.path.join(SOURCE_PATH, file_name)\n",
        "        if os.path.isfile(full_file_name) and not file_name.startswith('.'):\n",
        "            shutil.copy2(full_file_name, DESTINATION_PATH)\n",
        "            print(f\"📥 Loaded: {file_name}\")\n",
        "            count += 1\n",
        "\n",
        "    if count == 0:\n",
        "        print(\"Folder is empty.\")\n",
        "    else:\n",
        "        print(\"-\" * 30)\n",
        "        print(f\"Successfully loaded {count} files from Drive.\")\n",
        "else:\n",
        "    print(f\"❌ Error: Folder '{SOURCE_PATH}' not found on Google Drive.\")\n",
        "    print(\"Please run the 'Save to Drive' cell first or create the folder manually.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "743103ca1d6d4c2bbbb0a6641be8842e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01441ef57d044a749fe934712758e209",
              "IPY_MODEL_10ff74fdea14428ab9aebb64768a9f90",
              "IPY_MODEL_e1687840b552470d91e4583ae6150400"
            ],
            "layout": "IPY_MODEL_a2a70190b1824ca4a9565926761553a1"
          }
        },
        "01441ef57d044a749fe934712758e209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d10fc4429c134215bc9834bbb29956b5",
            "placeholder": "​",
            "style": "IPY_MODEL_c7f997ce9c524b5ebf15bb74e35c1ad2",
            "value": "Batches: 100%"
          }
        },
        "10ff74fdea14428ab9aebb64768a9f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b52821cda75c4c8fbc093f2a1199e0a4",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e276244cf0014f0682f880e45b716ba5",
            "value": 872
          }
        },
        "e1687840b552470d91e4583ae6150400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_040daca9a0924acf9418326303ab142a",
            "placeholder": "​",
            "style": "IPY_MODEL_3850205b87cf4772be82fd1072f0079d",
            "value": " 872/872 [01:25&lt;00:00, 43.70it/s]"
          }
        },
        "a2a70190b1824ca4a9565926761553a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d10fc4429c134215bc9834bbb29956b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f997ce9c524b5ebf15bb74e35c1ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b52821cda75c4c8fbc093f2a1199e0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e276244cf0014f0682f880e45b716ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "040daca9a0924acf9418326303ab142a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3850205b87cf4772be82fd1072f0079d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e363977aa3194a46a43da56bb13c2c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62d666ef109349278c3196c9bbd54ba4",
              "IPY_MODEL_72ac1e45f1c4437a87647def66c2dd2a",
              "IPY_MODEL_6c5aec51640d40faa04fbf609cc52f91"
            ],
            "layout": "IPY_MODEL_aaf40588d360480c8135edbaa0c1622b"
          }
        },
        "62d666ef109349278c3196c9bbd54ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d877a2d9f546b49f6eb46429a1e5fd",
            "placeholder": "​",
            "style": "IPY_MODEL_858de7570ccd41d398175dd1d86c7bfa",
            "value": "100%"
          }
        },
        "72ac1e45f1c4437a87647def66c2dd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75efa02d069043cc9d73c7d155f94a16",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be629881cb914132bd4c5736ed109221",
            "value": 15
          }
        },
        "6c5aec51640d40faa04fbf609cc52f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59657b5a05f041b2a8f362aac76abcf9",
            "placeholder": "​",
            "style": "IPY_MODEL_245de16688ad4f3093054604ed0b068f",
            "value": " 15/15 [00:00&lt;00:00, 57.03it/s]"
          }
        },
        "aaf40588d360480c8135edbaa0c1622b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d877a2d9f546b49f6eb46429a1e5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "858de7570ccd41d398175dd1d86c7bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75efa02d069043cc9d73c7d155f94a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be629881cb914132bd4c5736ed109221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59657b5a05f041b2a8f362aac76abcf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "245de16688ad4f3093054604ed0b068f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f5beb30fc9d448eb98a3809800e7682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc088e47e8f442b38a196616ffe3cd38",
              "IPY_MODEL_aab0e9aae1a949cdae837a079c64260c",
              "IPY_MODEL_426692e0186b494faf5c448a45cd0741"
            ],
            "layout": "IPY_MODEL_5b5eef9d7ac44613a827c2b940e92a3d"
          }
        },
        "cc088e47e8f442b38a196616ffe3cd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca244d9636454685a0335326bf6be460",
            "placeholder": "​",
            "style": "IPY_MODEL_18ba7ac8ba544e1fb6772330ffe34d0a",
            "value": "100%"
          }
        },
        "aab0e9aae1a949cdae837a079c64260c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e985af947c844670aed47c14504eeca1",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b54a0702c7d14a29b98eca6123a65314",
            "value": 15
          }
        },
        "426692e0186b494faf5c448a45cd0741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46aa14e0f88340dfbfacbe8259fad255",
            "placeholder": "​",
            "style": "IPY_MODEL_067ef0e4b06b430f91c439cd94fb1169",
            "value": " 15/15 [00:00&lt;00:00, 96.53it/s]"
          }
        },
        "5b5eef9d7ac44613a827c2b940e92a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca244d9636454685a0335326bf6be460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ba7ac8ba544e1fb6772330ffe34d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e985af947c844670aed47c14504eeca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b54a0702c7d14a29b98eca6123a65314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46aa14e0f88340dfbfacbe8259fad255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067ef0e4b06b430f91c439cd94fb1169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
