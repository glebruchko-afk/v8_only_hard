Отчет об использовании инструментов ИИ

В данном проекте технологии искусственного интеллекта использовались как основной инструмент написания программного кода под строгим руководством и архитектурным контролем участника.
В качестве основного инструмента использовалась бесплатная версия модели Google Gemini 3.0 через сервис Google AI Studio.

Методология работы
Работа строилась по принципу разделения ролей, где участник выступал в роли архитектора системы, а ИИ выполнял роль программиста.
Участник формулировал идеи, алгоритмы и требования к обработке данных.
Нейросеть генерировала базовый код для реализации этих идей.
Участник проверял код, объединял разрозненные блоки в единый пайплайн и устранял логические ошибки.
Детальное описание вклада ИИ и человека

1. Написание кода и библиотеки
ИИ сгенерировал большую часть синтаксических конструкций для работы со следующими библиотеками:
Pandas и Numpy: для обработки табличных данных и векторизации.
Implicit: для реализации матричной факторизации (ALS).
CatBoost: для настройки и обучения модели ранжирования.
Scikit-learn и Transformers: для создания текстовых эмбеддингов.

2. Генерация сложных негативов (Hard Negatives)
Логика создания обучающей выборки была продиктована человеком, но реализована силами ИИ. Участник поставил задачу реализовать добавление Hard Negatives — примеров, где модель ALS ошибается, чтобы обучить бустинг исправлять эти ошибки. ИИ написал код для генерации таких примеров и их слияния с основным датасетом.

3. Инжиниринг признаков (Feature Engineering)
Процесс создания новых признаков происходил в итеративном режиме. Участник предлагал идеи (например, добавить статистики по авторам, временные признаки или текстовые векторы), а ИИ генерировал соответствующий код для Pandas. Участник заставлял модель переписывать код до тех пор, пока реализация не становилась оптимальной по памяти и скорости.

4. Контроль утечек данных (Data Leakage)
Это была ключевая зона ответственности человека. При генерации кода нейросеть часто допускала ошибки, ведущие к утечке данных из будущего в прошлое (data leakage). Участник вручную проверял каждый сгенерированный блок кода, особенно при расчете статистик и OOF-предсказаний, и заставлял ИИ переписывать алгоритмы так, чтобы гарантировать честную валидацию.

5. Сборка и интеграция
Нейросеть выдавала код отдельными фрагментами. Сборка этих фрагментов в работающий Jupyter Notebook, отладка совместимости типов данных и финальный запуск производились участником вручную.
